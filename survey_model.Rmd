---
title: "Model lasu losowego na danych ankietowych - część 2"
author: "Bartosz Dąbrowski"
date: "30 05 2020"
output: html_document
---
# Wczytanie danych

```{r echo=FALSE, message=FALSE, warning=FALSE}
require(tidyverse)
require(stringr)
require(tm)
require(randomForest)
require(Metrics)
require(viridis)
require(ggpubr)
#require(rstatix)
#require(tibble)
#require(ggplot2)
```

Import przygotowanych danych i delikatne zmiany.

```{r echo=FALSE, message=FALSE}
set.seed(42)
data <- read.table("E:/survey_model/dane_ankieta.tsv",sep="\t",header=TRUE,fileEncoding = "UTF-8", check.names=FALSE)
```


```{r echo=FALSE}
data[,27]<-as.factor(data[,27])
```

Na potrzeby modelu, usunąć należy kolumny bez zdolności predykcyjnej - sygnaturę czasową, dobrowolny feedback oraz pytanie o miejsce zamieszkanie w trakcie studiów, które zostało już rozbite na 5 zmiennych zero-jedynkowych.

```{r echo=FALSE}
df0<-data[,-28]
df0<-df0[,-17]
df0<-df0[,-1]
```

Dla większej czytelności zmieniono nazwy kolumn.

```{r echo=FALSE}
colnames(df0)[1:31]<-c('Kobieta','Wiek','Wojewodztwo_pochodzenia', 'Wielkosc_miasta', 'Miasto', 'Wiecej_kierunkow', 'Rok','Prywatna','Zaocznie', 'Typ','Kola','Organizacje','Samorzad','Srednia','Stypendium','Wiodace','Zapychacze','Zapychacze_dobor','Jezyk','Organizacja_uczelni','Plany','Trudnosc','Przydatnosc','Ogolna_ocena','Praca','Akademik','Dom_mieszkanie_rodzinne','Wynajete_mieszkanie','Wynajety_pokoj','Inne','Dyscyplina')
colnames(df0)
df<-df0
```

# MODELE

```{r echo=FALSE}
model1<-randomForest(Praca~.,data=df,ntree=1000,mtry=5,importance=TRUE)
print(model1)
importance(model1,class=TRUE)
```

Wykres modelu przedstawia kształtowanie się błędu poza próbką w raz ze wzrostem liczby drzew. Po gwałtownym zmniejszaniu do około 200, następuje stablizacja. Zielona linia oznacza błąd w klasyfikacji pracujących, czerwona - niepracujących, a czarna - uśredniony dla obu grup.

```{r echo=FALSE}
plot(model1)
auc_model<-auc(df$Praca,model1$predicted)
err<-(model1$confusion[2]+model1$confusion[3])/nrow(df)
acc<-(model1$confusion[1]+model1$confusion[4])/nrow(df)
sens<-model1$confusion[1]/(model1$confusion[1]+model1$confusion[3])
spec<-model1$confusion[4]/(model1$confusion[4]+model1$confusion[2])
gmean<-sqrt(sens*spec)
recall<-model1$confusion[1]/(model1$confusion[1]+model1$confusion[2])
prec<-model1$confusion[1]/(model1$confusion[1]+model1$confusion[3])
cat("AUC: ", auc_model,"\nOOB Error: ", err,"\nAccuracy: ", acc,"\nSensitivity: ", sens,"\nSpecifity: ", spec,"\nG-Mean: ", gmean,"\nRecall: ", recall,"\nPrecision: ", prec)
```

Pierwszy zbudowany model cechuje stosunkowa dobra dokładność - ponad 70%. Ma dość wysoką czułość kosztem niskiej swoistości - wiąże się to z dużo lepszym wykrywaniem bezrobotnych, podczas gdy skuteczność w przypadku pracujących wynosi niewiele ponad 50%. Najprawdopodobniej wpływ na to ma dysproporcja w próbkach. W następnym modelu zostaną one wyrównane.

## Model z wyrównanymi próbkami

```{r echo=FALSE}
model2<-randomForest(Praca~.,data=df,ntree=1000,mtry=5,importance=TRUE,sampsize=c(155,155))
print(model2)
importance(model2,class=TRUE)
```

```{r echo=FALSE}
plot(model2)
auc_model<-auc(df$Praca,model2$predicted)
err<-(model2$confusion[2]+model2$confusion[3])/nrow(df)
acc<-(model2$confusion[1]+model2$confusion[4])/nrow(df)
sens<-model2$confusion[1]/(model2$confusion[1]+model2$confusion[3])
spec<-model2$confusion[4]/(model2$confusion[4]+model2$confusion[2])
gmean<-sqrt(sens*spec)
recall<-model2$confusion[1]/(model2$confusion[1]+model2$confusion[2])
prec<-model2$confusion[1]/(model2$confusion[1]+model2$confusion[3])
cat("AUC: ", auc_model,"\nOOB Error: ", err,"\nAccuracy: ", acc,"\nSensitivity: ", sens,"\nSpecifity: ", spec,"\nG-Mean: ", gmean,"\nRecall: ", recall,"\nPrecision: ", prec)
```

Ogólna skuteczność uległa pogorszeniu. W zamian za to, wyrównaniu uległy czułość i swoistość, i model radzi sobie z klasyfikacją obu grup w podobnym stopniu. Pomimo nieco gorszych wyników, ma on większą wartość.

## PODZIAŁ NA DANE TESTOWE I TRENINGOWE

Po "testowych" modelach na całości danych, przyjęto wstępnie podział 70% dla danych uczących i 30% dla testowych.

```{r echo=FALSE}
n <- nrow(df)
n_train <- round(0.7 * n) 
train_indices <- sample(1:n, n_train)
df_train <- df[train_indices, ]  
df_test <- df[-train_indices, ]  
```

```{r echo=FALSE}
table(df_train$Praca)
model_train<-randomForest(Praca~.,data=df_train,ntree=1000,mtry=5,importance=TRUE,sampsize=c(104,104))
print(model_train)
importance(model_train,class=TRUE)
```

```{r echo=FALSE}
plot(model_train)
```

```{r echo=FALSE}
test_rf<-predict(model_train,newdata=df_test)
mtx<-as.matrix(table(test_rf,df_test$Praca))
auc_model<-auc(df_test$Praca,test_rf)
err<-(mtx[2]+mtx[3])/nrow(df_test)
acc<-(mtx[1]+mtx[4])/nrow(df_test)
sens<-mtx[1]/(mtx[1]+mtx[3])
spec<-mtx[4]/(mtx[4]+mtx[2])
gmean<-sqrt(sens*spec)
recall<-mtx[1]/(mtx[1]+mtx[2])
prec<-mtx[1]/(mtx[1]+mtx[3])
cat("AUC: ", auc_model,"\nOOB Error: ", err,"\nAccuracy: ", acc,"\nSensitivity: ", sens,"\nSpecifity: ", spec,"\nG-Mean: ", gmean,"\nRecall: ", recall,"\nPrecision: ", prec)
```

## Próba wykluczenia z modelu obserwacji o wątpliwej wiarygodności

Niektórzy z respondentów w pytaniu o feedback zgłaszali problemy z ankietą - najczęściej były to wątpliwości co do przypisania swojej uczelni bądź kierunku, niekiedy niepewność co do właściwego interpretowania swojej pracy - czy jest ona związana ze studiami. Do następnego modelu wykorzystane zostaną dane oczyszczone z takich obserwacji.

```{r echo=FALSE, message=FALSE,warning=FALSE}
df1<-df0[,-17]
df1<-df1[,-1]
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#df0[!(is.na(df0[,26])),25:26] #analiza feedbacku - respondenci zgłaszający problemy z zaznaczeniem odpowiadających ich sytuacji opcji zostaną usunięci z danych
df2<-df1[-c(60, 103, 240, 244, 258,276, 321,345,347,348,366,87, 264),-26]
```

```{r echo=FALSE}
table(df2$Praca)
model3<-randomForest(Praca~.,data=df2,ntree=1000,mtry=5,importance=TRUE,sampsize=c(150,150))
print(model3)
importance(model3,class=TRUE)
```

```{r echo=FALSE}
plot(model3) #zielony - pracuję, czarny - średni, czerwony - jeszcze nie
varImpPlot(model3)
```

Po gwałtownym zmniejszaniu do około 350, następuje stablizacja, najniższe wartości osiągając w granicach 600 i ustrzymując się od tej pory na stosunkowo stabilnym poziomie. Zielona linia oznacza błąd w klasyfikacji pracujących, czerwona - niepracujących, a czarna - uśredniony dla obu grup.

```{r echo=FALSE}
auc_model<-auc(df2$Praca,model3$predicted)
err<-(model3$confusion[2]+model3$confusion[3])/400
acc<-(model3$confusion[1]+model3$confusion[4])/400
sens<-model3$confusion[1]/(model3$confusion[1]+model3$confusion[3])
spec<-model3$confusion[4]/(model3$confusion[4]+model3$confusion[2])
gmean<-sqrt(sens*spec)
recall<-model3$confusion[1]/(model3$confusion[1]+model3$confusion[2])
prec<-model3$confusion[1]/(model3$confusion[1]+model3$confusion[3])
cat("AUC: ", auc_model,"\nOOB Error: ", err,"\nAccuracy: ", acc,"\nSensitivity: ", sens,"\nSpecifity: ", spec,"\nG-Mean: ", gmean,"\nRecall: ", recall,"\nPrecision: ", prec)
```

Z 13 usuniętych przypadków, 8 było błędni klasyfikowanych - 5 pracujących było uznawanych za bezrobotnych, 3 bezrobotnych - za pracujących. Przyniosło to delikatną poprawę; jest to najlepszy z dotychczasowych modeli na pełnych danych.

### Model oczyszczony z wątpliwych obserwacji z podziałem na dane treningowe i testowe

Podobnie jak wcześniej, przyjmuję podział 0,7:0,3.

```{r echo=FALSE}
n <- nrow(df2)
n_train <- round(0.7 * n) 
train_indices <- sample(1:n, n_train)
df_train2 <- df2[train_indices, ]  
df_test2 <- df2[-train_indices, ]  
```

```{r echo=FALSE}
table(df_train2$Praca)
model_train2<-randomForest(Praca~.,data=df_train2,ntree=1000,mtry=5,importance=TRUE,sampsize=c(104,104))
print(model_train2)
importance(model_train2,class=TRUE)
```

```{r echo=FALSE}
cat("AUC na danych treningowych: ", auc(df_train2$Praca,model_train2$predicted))
```

```{r echo=FALSE}
test_rf<-predict(model_train2,newdata=df_test2)
mtx<-as.matrix(table(test_rf,df_test2$Praca))
auc_model<-auc(df_test2$Praca,test_rf)
err<-(mtx[2]+mtx[3])/nrow(df_test2)
acc<-(mtx[1]+mtx[4])/nrow(df_test2)
sens<-mtx[1]/(mtx[1]+mtx[3])
spec<-mtx[4]/(mtx[4]+mtx[2])
gmean<-sqrt(sens*spec)
recall<-mtx[1]/(mtx[1]+mtx[2])
prec<-mtx[1]/(mtx[1]+mtx[3])
cat("AUC: ", auc_model,"\nOOB Error: ", err,"\nAccuracy: ", acc,"\nSensitivity: ", sens,"\nSpecifity: ", spec,"\nG-Mean: ", gmean,"\nRecall: ", recall,"\nPrecision: ", prec)
```
