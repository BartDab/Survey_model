---
title: "Model lasu losowego na danych ankietowych"
author: "Bartosz Dąbrowski"
date: "3 05 2020"
output: html_document
---

# Wczytanie danych

```{r echo=FALSE, message=FALSE, warning=FALSE}
require(tidyverse)
require(stringr)
require(tm)
require(randomForest)
require(Metrics)
```

Pierwszym etapem jest import i podgląd danych do analizy.

```{r echo=FALSE, message=FALSE}
set.seed(42)
data <- read_delim("E:/survey_model/dane_2.tsv", "\t", 
    escape_double = FALSE, trim_ws = TRUE)
```


```{r}
head(data,10)
```

# Oczyszczanie danych

Zmiana kolumn w formacie __str__ na __factor__.

```{r}
data<-as.data.frame(data)
data[,4]<-parse_factor(data[,4],levels=unique(sort(data[,4])))
data[,5]<-parse_factor(data[,5],levels=c("poniżej 5 tysięcy","5 - 20 tysięcy","20 - 100 tysięcy", "100 - 200 tysięcy","200 - 500 tysięcy","powyżej 500 tysięcy"))
data[,8]<-parse_factor(data[,8],levels=c('I','II','III','IV','V','Ukończyłem/ukończyłam studia'))
data[,11]<-parse_factor(data[,11],levels=c("Artystyczna","Ekonomiczna","Pedagogiczna","Techniczna","Uniwersytet","Inna"))
data[,12]<-parse_factor(data[,12],levels=c("Architektura","Automatyka/elektrotechnika","Biologia","Chemia","Dziennikarstwo/komunikacja społeczna","Ekonometria","Ekonomia/finanse","Farmacja","Filologia","Fizyka/astronomia","Geografia","Historia","Informatyka/telekomunikacja","Inżynieria biomedyczna","Inżynieria chemiczna","Inżynieria lądowa/budownictwo/transport","Inżynieria materiałowa","Inżynieria mechaniczna","Inżynieria środowiska/energetyka/górnictwo","Kulturoznawstwo/religioznawstwo","Matematyka","Medycyna","Nauki o bezpieczeństwie","Pedagogika","Prawo/administracja","Psychologia","Socjologia","Sztuki piękne","Technologia żywności","Weterynaria/zootechnika","Zarządzanie","Inne"))
data[,16]<-parse_factor(data[,16],levels=unique(sort(data[,16])))
data[,28]<-parse_factor(data[,28],levels=c("Jeszcze nie pracuję","Przed początkiem studiów","I rok","II rok", "III rok","IV rok","V rok", "Później"))
```


Oczyszczanie odpowiedzi - ujednolicenie odpowiedzi bez polskich znaków, z literówkami, dodatkowymi komentarzamim, a także połączenie tych miast, w przypadku których nie ma różnicy w dostępie do pracy, uczelni czy w średnich cenach, i które w praktyce można niemal traktować jak jedno miasto - Trójmiasto oraz Górnośląski Okręg Przemysłowy.

Przed:

```{r echo=FALSE}
table(data[,6])
```


```{r echo=FALSE}
data[,3] <- replace(data[,3],data[,3]=="19, rocznikowo 20", "19")
data[,3]<-as.numeric(data[,3])
wektor<-c('Kraków','Krakow','krk','Krakó','Kraków xD')
data[,6]<-gsub(paste(wektor, collapse = '|'), 'Kraków', data[,6])
wektor<-c('Warszawa','Wawa','Warszasa')
data[,6]<-gsub(paste(wektor, collapse = '|'), 'Warszawa', data[,6])
wektor<-c("Poznań","poznań","Poznan")
data[,6]<-gsub(paste(wektor, collapse = '|'), 'Poznań', data[,6])
wektor<-c('Gdańsk','Gdansk')
data[,6]<-gsub(paste(wektor, collapse = '|'), 'Gdańsk', data[,6])
wektor<-c("BIAŁYSTOK", "Białystok")
data[,6]<-gsub(paste(wektor, collapse = '|'), 'Białystok', data[,6])
wektor<-c("słupsk", "Słupsk")
data[,6]<-gsub(paste(wektor, collapse = '|'), 'Słupsk', data[,6])
wektor<-c("Deblin", "Dęblin")
data[,6]<-gsub(paste(wektor, collapse = '|'), 'Dęblin', data[,6])
wektor<-c("Toruń, Poznań", "Toruń")
data[,6]<-gsub(paste(wektor, collapse = '|'), 'Toruń', data[,6])
data[,6] <- replace(data[,6],data[,6]=="Uniwersytet Śląski", "Katowice")
wektor<-c('Gdańsk','Gdynia','Sopot')
data[,6]<-gsub(paste(wektor, collapse = '|'), 'Trójmiasto', data[,6])
wektor<-c('Katowice','Bytom','Gliwice','Sosnowiec','Zabrze')
data[,6]<-gsub(paste(wektor, collapse = '|'), 'Katowice', data[,6])
data[,6]<-parse_factor(data[,6],levels=unique(sort(data[,6])))
```

Po:

```{r echo=FALSE}
table(data[,6])
```

W przypadku kolumn z 2 możliwymi odpowiedziami, można je zamienić na zmienne zero-jedynkowe.

```{r}
data[,2]<-if_else(data[,2]=="Kobieta",1,0)
data[,9]<-if_else(data[,9]=="Prywatna",1,0)
data[,10]<-if_else(data[,10]=="Zaocznie",1,0)
data[,7]<-if_else(data[,7]=="Tak",1,0)
data[,13:15]<-if_else(data[,13:15]=="Tak",1,0)
data[,17]<-if_else(data[,17]=="Tak",1,0)
```

Odpowiedzi do pytania o lokum wyeksportowane zostały w formie tekstowej, z zaznaczonymi opcjami wymienionymi po przecinku. Aby je wyodrębnić do osobnych kolumn, zastosowano kombinację __if_else__ i __str_detect__ z pakietu *stringr*.

```{r}
data<-data%>%
  mutate(Akademik=if_else(str_detect(data[,18],coll("Akademik")),1,0),
         Dom_mieszkanie_rodzinne=if_else(str_detect(data[,18],coll("Dom/mieszkanie rodzinne")),1,0),
         Wynajete_mieszkanie=if_else(str_detect(data[,18],coll("Wynajęte mieszkanie")),1,0),
         Wynajety_pokoj=if_else(str_detect(data[,18],coll("Wynajęty pokój")),1,0),
         Inne=if_else(str_detect(data[,18],coll("Inne")),1,0))
```


Tworząc ankietę, użyty został aktualny podział na dziedziny ustalonego przez Ministerstwo Szkolnictwa Wyższego. Zmienna o 32 możliwych wartościach ma jednak niską wartość predykcyjną i zwiększa ryzyko wykrycia fałszywych korelacji (zwłaszcza w przypadku kierunków z niską liczbą respondentów). W tym celu zostaną one zastąpione przypisaniem do dyscyplin, które, choć niedokładne, pozwalają na większe uogólnienie i generalizację.

Przed:

```{r echo=FALSE}
levels(data[,12])
```

```{r}
data<-data%>%
  mutate(Dyscyplina = ifelse(data[,12] %in% c('Biologia','Chemia', 'Geografia'),'Nauki przyrodnicze',ifelse(data[,12]  %in% c('Psychologia','Socjologia','Zarządzanie','Nauki o bezpieczeństwie','Pedagogika','Ekonomia/finanse','Ekonometria','Prawo/administracja','Dziennikarstwo/komunikacja społeczna'),'Nauki spoleczne',ifelse(data[,12]  %in% c('Inżynieria biomedyczna','Inżynieria chemiczna','Inżynieria materiałowa','Inżynieria mechaniczna','Inżynieria środowiska/energetyka/górnictwo','Inżynieria lądowa/budownictwo/transport',"Architektura","Automatyka/elektrotechnika"),'Nauki inzynieryjno-techniczne',ifelse(data[,12]  %in% c('Historia','Kulturoznawstwo/religioznawstwo',"Filologia"),'Nauki humanistyczne',ifelse(data[,12]  %in% c('Medycyna','Farmacja'),'Nauki o zdrowiu',ifelse(data[,12]  %in% c('Fizyka/astronomia','Informatyka/telekomunikacja',"Matematyka"),'Nauki scisle',ifelse(data[,12]  %in% c("Technologia żywności","Weterynaria/zootechnika" ),'Nauki rolnicze',levels(data[,12])[`Jaka dziedzina nauk najlepiej określa Twoje studia?`]))))))))
data[,35]<-parse_factor(data[,35],levels=unique(sort(data[,35])))
data<-data[,-12]
```

Po:

```{r echo=FALSE}
levels(data[,34])
```

Ostatnim elementem jest uproszczenie outputu - opcja niepracująca to ponad 60% odpowiedzi, podczas gdy II stopień i "później" łącznie to niespełna 5%. Aby to wyrównać, zastosowano generalizację wszystkich opcji "pracujących" i połączenie w jedną, o reprezentacji w danych wynoszącej blisko 40%. **1** oznacza osoby pracujące, **0** - nie.

Przed:

```{r echo=FALSE}
table(data[,27])
```

Po:

```{r echo=FALSE}
data[,27]<-if_else(data[,27]=="Jeszcze nie pracuję",0,1)
data[,27]<-as.factor(data[,27])
table(data[,27])
```

Na potrzeby modelu, usunąć należy kolumny bez zdolności predykcyjnej - sygnaturę czasową, dobrowolny feedback oraz pytanie o miejsce zamieszkanie w trakcie studiów, które zostało już rozbite na 5 zmiennych zero-jedynkowych.

```{r echo=FALSE}
df0<-data[,-28]
df0<-df0[,-17]
df0<-df0[,-1]
```

Dla większej czytelności zmieniono nazwy kolumn.

```{r echo=FALSE}
colnames(df0)[1:31]<-c('Kobieta','Wiek','Wojewodztwo_pochodzenia', 'Wielkosc_miasta', 'Miasto', 'Wiecej_kierunkow', 'Rok','Prywatna','Zaocznie', 'Typ','Kola','Organizacje','Samorzad','Srednia','Stypendium','Wiodace','Zapychacze','Zapychacze_dobor','Jezyk','Organizacja_uczelni','Plany','Trudnosc','Przydatnosc','Ogolna_ocena','Praca','Akademik','Dom_mieszkanie_rodzinne','Wynajete_mieszkanie','Wynajety_pokoj','Inne','Dyscyplina')
colnames(df0)
df<-df0
```

# MODELE

```{r echo=FALSE}
model1<-randomForest(Praca~.,data=df,ntree=1000,mtry=5,importance=TRUE)
print(model1)
importance(model1,class=TRUE)
```

```{r echo=FALSE}
plot(model1)
auc_model<-auc(df$Praca,model1$predicted)
err<-(model1$confusion[2]+model1$confusion[3])/nrow(df)
acc<-(model1$confusion[1]+model1$confusion[4])/nrow(df)
sens<-model1$confusion[1]/(model1$confusion[1]+model1$confusion[3])
spec<-model1$confusion[4]/(model1$confusion[4]+model1$confusion[2])
gmean<-sqrt(sens*spec)
recall<-model1$confusion[1]/(model1$confusion[1]+model1$confusion[2])
prec<-model1$confusion[1]/(model1$confusion[1]+model1$confusion[3])
cat("AUC: ", auc_model,"\nOOB Error: ", err,"\nAccuracy: ", acc,"\nSensitivity: ", sens,"\nSpecifity: ", spec,"\nG-Mean: ", gmean,"\nRecall: ", recall,"\nPrecision: ", prec)
```

Pierwszy zbudowany model cechuje stosunkowa dobra dokładność - 72,5%. Ma dość wysoką czułość kosztem niskiej swoistości - wiąże się to z dużo lepszym wykrywaniem bezrobotnych, podczas gdy skuteczność w przypadku pracujących wynosi niewiele ponad 50%. Najprawdopodobniej wpływ na to ma dysproporcja w próbkach. W następnym modelu zostaną one wyrównane.

## Model z wyrównanymi próbkami

```{r echo=FALSE}
model2<-randomForest(Praca~.,data=df,ntree=1000,mtry=5,importance=TRUE,sampsize=c(155,155))
print(model2)
importance(model2,class=TRUE)
```

```{r echo=FALSE}
plot(model2)
auc_model<-auc(df$Praca,model2$predicted)
err<-(model2$confusion[2]+model2$confusion[3])/nrow(df)
acc<-(model2$confusion[1]+model2$confusion[4])/nrow(df)
sens<-model2$confusion[1]/(model2$confusion[1]+model2$confusion[3])
spec<-model2$confusion[4]/(model2$confusion[4]+model2$confusion[2])
gmean<-sqrt(sens*spec)
recall<-model2$confusion[1]/(model2$confusion[1]+model2$confusion[2])
prec<-model2$confusion[1]/(model2$confusion[1]+model2$confusion[3])
cat("AUC: ", auc_model,"\nOOB Error: ", err,"\nAccuracy: ", acc,"\nSensitivity: ", sens,"\nSpecifity: ", spec,"\nG-Mean: ", gmean,"\nRecall: ", recall,"\nPrecision: ", prec)
```

Ogólna skuteczność, jak i AUC uległo pogorszeniu. W zamian za to, wyrównaniu uległy czułość i swoistość, i model radzi sobie z klasyfikacją obu grup w podobnym stopniu. Pomimo nieco gorszych wyników, ma on większą wartość.

## PODZIAŁ NA DANE TESTOWE I TRENINGOWE

Przyjmuję wstępnie podział 70% dla danych uczących i 30% dla testowych.

```{r echo=FALSE}
n <- nrow(df)
n_train <- round(0.7 * n) 
train_indices <- sample(1:n, n_train)
df_train <- df[train_indices, ]  
df_test <- df[-train_indices, ]  
```

```{r echo=FALSE}
table(df_train$Praca)
model_train<-randomForest(Praca~.,data=df_train,ntree=1000,mtry=5,importance=TRUE,sampsize=c(100,100))
print(model_train)
importance(model_train,class=TRUE)
```

```{r echo=FALSE}
plot(model_train)
```

```{r echo=FALSE}
test_rf<-predict(model_train,newdata=df_test)
mtx<-as.matrix(table(test_rf,df_test$Praca))
auc_model<-auc(df_test$Praca,test_rf)
err<-(mtx[2]+mtx[3])/nrow(df_test)
acc<-(mtx[1]+mtx[4])/nrow(df_test)
sens<-mtx[1]/(mtx[1]+mtx[3])
spec<-mtx[4]/(mtx[4]+mtx[2])
gmean<-sqrt(sens*spec)
recall<-mtx[1]/(mtx[1]+mtx[2])
prec<-mtx[1]/(mtx[1]+mtx[3])
cat("AUC: ", auc_model,"\nOOB Error: ", err,"\nAccuracy: ", acc,"\nSensitivity: ", sens,"\nSpecifity: ", spec,"\nG-Mean: ", gmean,"\nRecall: ", recall,"\nPrecision: ", prec)
```

Sytuacja w tym momencie wydaje się dość zastanawiająca. Wyniki na zbiorze testowym prezentują się lepiej, niż na treningowym - jest niższy błąd, AUC wygląda lepiej, niż w poprzednich modelach. Nie do końca wiem, gdzie (i czy) robię błąd.

## Próba wykluczenia z modelu obserwacji o wątpliwej wiarygodności

Niektórzy z respondentów w pytaniu o feedback zgłaszali problemy z ankietą - najczęściej były to wątpliwości co do przypisania swojej uczelni bądź kierunku, niekiedy niepewność co do właściwego interpretowania swojej pracy - czy jest ona związana ze studiami. Do następnego modelu wykorzystane zostaną dane oczyszczone z takich obserwacji.

```{r echo=FALSE, message=FALSE,warning=FALSE}
df1<-df0[,-17]
df1<-df1[,-1]
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#df0[!(is.na(df0[,26])),25:26] #analiza feedbacku - respondenci zgłaszający problemy z zaznaczeniem odpowiadających ich sytuacji opcji zostaną usunięci z danych
df2<-df1[-c(60, 103, 240, 244, 258,276, 321,345,347,348,366,87, 264),-26]
```

```{r echo=FALSE}
table(df2$Praca)
model3<-randomForest(Praca~.,data=df2,ntree=1000,mtry=5,importance=TRUE,sampsize=c(150,150))
print(model3)
importance(model3,class=TRUE)
```

```{r echo=FALSE}
plot(model3) #zielony - pracuję, czarny - średni, czerwony - jeszcze nie
varImpPlot(model3)
```

Wykres modelu przedstawia kształtowanie się błędu poza próbką w raz ze wzrostem liczby drzew. Po gwałtownym zmniejszaniu do około 350, następuje stablizacja, najniższe wartości osiągając w granicach 700 i ustrzymując się od tej pory na stosunkowo stabilnym poziomie. Zielona linia oznacza błąd w klasyfikacji pracujących, czerwona - niepracujących, a czarna - uśredniony dla obu grup.

```{r echo=FALSE}
auc_model<-auc(df2$Praca,model3$predicted)
err<-(model3$confusion[2]+model3$confusion[3])/400
acc<-(model3$confusion[1]+model3$confusion[4])/400
sens<-model3$confusion[1]/(model3$confusion[1]+model3$confusion[3])
spec<-model3$confusion[4]/(model3$confusion[4]+model3$confusion[2])
gmean<-sqrt(sens*spec)
recall<-model3$confusion[1]/(model3$confusion[1]+model3$confusion[2])
prec<-model3$confusion[1]/(model3$confusion[1]+model3$confusion[3])
cat("AUC: ", auc_model,"\nOOB Error: ", err,"\nAccuracy: ", acc,"\nSensitivity: ", sens,"\nSpecifity: ", spec,"\nG-Mean: ", gmean,"\nRecall: ", recall,"\nPrecision: ", prec)
```

Z 13 usuniętych przypadków, 8 było błędni klasyfikowanych - 5 pracujących było uznawanych za bezrobotnych, 3 bezrobotnych - za pracujących. Przyniosło to delikatną poprawę; jest to najlepszy z dotychczasowych modeli na pełnych danych.

### Model oczyszczony z wątpliwych obserwacji z podziałem na dane treningowe i testowe

Podobnie jak wcześniej, przyjmuję podział 0,7:0,3.

```{r echo=FALSE}
n <- nrow(df2)
n_train <- round(0.7 * n) 
train_indices <- sample(1:n, n_train)
df_train2 <- df2[train_indices, ]  
df_test2 <- df2[-train_indices, ]  
```

```{r echo=FALSE}
table(df_train2$Praca)
model_train2<-randomForest(Praca~.,data=df_train2,ntree=1000,mtry=5,importance=TRUE,sampsize=c(100,100))
print(model_train2)
importance(model_train2,class=TRUE)

(auc(df_train2$Praca,model_train2$predicted))
```

```{r echo=FALSE}
test_rf<-predict(model_train2,newdata=df_test2)
mtx<-as.matrix(table(test_rf,df_test2$Praca))
auc_model<-auc(df_test2$Praca,test_rf)
err<-(mtx[2]+mtx[3])/nrow(df_test2)
acc<-(mtx[1]+mtx[4])/nrow(df_test2)
sens<-mtx[1]/(mtx[1]+mtx[3])
spec<-mtx[4]/(mtx[4]+mtx[2])
gmean<-sqrt(sens*spec)
recall<-mtx[1]/(mtx[1]+mtx[2])
prec<-mtx[1]/(mtx[1]+mtx[3])
cat("AUC: ", auc_model,"\nOOB Error: ", err,"\nAccuracy: ", acc,"\nSensitivity: ", sens,"\nSpecifity: ", spec,"\nG-Mean: ", gmean,"\nRecall: ", recall,"\nPrecision: ", prec)
```

Po raz kolejny skuteczność na danych testowych jest wyższa, niż na treningowych. Być może spowodowane jest to mniejszą liczbą danych.